{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBDtFXcBb8Td"
   },
   "source": [
    "## BIOENG-310: Neuroscience Foundations for Engineers\n",
    "\n",
    "Notebook created by Yingtian Tang, edited by Alejandro Rodriguez Guajardo.\n",
    "\n",
    "# Week 7: Graded exercise - Align to IT activity\n",
    "\n",
    "This week, we will test your understanding of what we've learned.\n",
    "We are shifting focus to data from the **inferior temporal gyrus (IT)** in monkeys. IT is a high-level region in the ventral visual stream, where neural populations encode object categories.\n",
    "In contrast, **V1**, which we previously worked with, is an early-stage area in the stream. The processing hierarchy from V1 to V2, V4, and IT progressively builds computations that support vision‚Äîfrom edge and color detection to object categorization.\n",
    "\n",
    "The notebook consists of the following sessions:\n",
    "- **Data visualization**:\n",
    "  * Visualize stimulus samples (1 points)\n",
    "  * Visualize stimulus-averaged neural response time series (2 points)\n",
    "  * Visualize time-averaged neural responses (2 points)\n",
    "- **Decode object category from IT activity** (3 points)\n",
    "- **Model alignment using RDM**\n",
    "  * Align Gabor filtering to IT activity (4 points)\n",
    "  * Align AlexNet to IT activity (3 points)\n",
    "\n",
    "The whole exercise is worth 15 points (15% of your final grade). You can navigate through these sections using the `Table of contents` on the left (in Google Colab).\n",
    "\n",
    "Please complete the tasks described in each section.\n",
    "You may use multiple consecutive Python code blocks to complete the tasks, but ensure they remain within the same section as the corresponding task.\n",
    "\n",
    "Enjoy the challenge! üèÜ\n",
    "\n",
    "**Before you begin**, execute the following block to install the required packages. (The following code might require you to *restart runtime*, which is fine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHKwr0d-F6gn"
   },
   "outputs": [],
   "source": [
    "!pip install jupyter brainscore-vision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nbufFyrlTW9R",
    "outputId": "2ead84b0-bfb9-4cd8-ad64-e29c96f12748"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import brainscore_vision\n",
    "from matplotlib import pyplot, image\n",
    "\n",
    "data = brainscore_vision.load_dataset('MajajHong2015.temporal.public')\n",
    "\n",
    "# we'll focus on only IT recordings in this exercise\n",
    "it_data = data.sel(region='IT')\n",
    "\n",
    "# to make our life easier, we only work on a subset of the data this time\n",
    "# this is going to take some time to load\n",
    "stimulus_ids = it_data['stimulus_id'].values\n",
    "target_stimuli = np.unique(stimulus_ids)[:135]\n",
    "stimulus_mask = [stimulus_id in target_stimuli for stimulus_id in stimulus_ids]\n",
    "it_data = it_data.isel(presentation=stimulus_mask)\n",
    "stimulus_set = it_data.stimulus_set\n",
    "stimulus_set = stimulus_set[stimulus_set['stimulus_id'].isin(target_stimuli)]\n",
    "it_data.attrs[\"stimulus_set\"] = stimulus_set\n",
    "\n",
    "it_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gtFvhNcVqJ-5"
   },
   "outputs": [],
   "source": [
    "# load the it_data to memory\n",
    "it_data = it_data.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Pr4_oZGGE5H"
   },
   "source": [
    "### Data visualization\n",
    "\n",
    "In this section, please try to visualize the following aspects of the data:\n",
    "1. **Stimulus samples:** example images shown to the monkeys.\n",
    "2. **Stimulus-averaged neural response time series:** firing rate time series averaged across all stimuli for each neural site.\n",
    "3. **Time-averaged neural responses:** mean firing rates computed over the 70~170 ms window for each neural site and each stimulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVcKO4a_U7HH"
   },
   "source": [
    "#### Visualize stimulus samples\n",
    "\n",
    "Please visualize the first 10 stimuli (images) from the stimulus set in grayscale.\n",
    "\n",
    "**Hint:** you can adapt the code from *exercise5 : Stimuli* for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "id": "e60U8ABQU6kN",
    "outputId": "a0465829-5165-4a8f-8896-dae3db530883"
   },
   "outputs": [],
   "source": [
    "'''%% Visualize the first 10 stimuli (images) from the stimulus set in grayscale. %%'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhJHSuy7itfe"
   },
   "source": [
    "#### Visualize stimulus-averaged neural response time series\n",
    "\n",
    "Please visualize the following:\n",
    "\n",
    "- **Per neural site:** The firing rate time series averaged across all stimuli for each neural site.\n",
    "- **Overall mean:** The average time series computed across all neural sites.\n",
    "\n",
    "For each stimulus, you should average across repetitions.\n",
    "\n",
    "**Hint:** you can adapt codes from *exercise5 : Data visualization*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Pq7hGWmUisNE",
    "outputId": "bce08d6d-33e1-47eb-e821-fb0944e4ebd9"
   },
   "outputs": [],
   "source": [
    "'''%% Visualize the per-neural-site and overall-mean firing rate time series, averaged across all stimuli. %%'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ASvd28qVtP9"
   },
   "source": [
    "#### Visualize time-averaged neural responses\n",
    "\n",
    "Please visualize a colormap matrix representing neural responses, with:\n",
    "\n",
    "- **Columns:** All stimuli, ordered according to `stimulus_set`.\n",
    "- **Rows:** All neural sites, ordered as in `it_data`.\n",
    "- **Color Encoding:** Mean firing rates within the 70~170 ms window. Use `'Greens'` as the `cmap`.\n",
    "\n",
    "For each stimulus, you should average across repetitions.\n",
    "\n",
    "**Hint:** you can adapt the code from *exercise5 : Time-averaging*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "KoUyXjH5VsRl",
    "outputId": "e5d01e6d-3685-4699-bd01-7f869a2e8163"
   },
   "outputs": [],
   "source": [
    "'''%% Visualize a colormap of shape [#stimuli x #neuroid], with color indicating the averaged firing rate from 70 to 170ms. %%'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6Zb4xdLZF24"
   },
   "source": [
    "### Decode object category from IT activity\n",
    "\n",
    "In this section, please try to decode the object category (the `category_name` coord in the `it_data`) using the time-averaged neural responses from the last section. There are in total 8 classes and 3200 different images in this case. **Please report the validation accuracy and compare it to the theoretical chance performance.**\n",
    "\n",
    "**Hint:** you can adapt codes from *exercise5 : Predicting/decoding the texture types*.\n",
    "\n",
    "Please use the train-test split and regressor given below. Also, normalize the inputs during the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiGV0i2IZZ_g"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED=3\n",
    "stimulus_ids = stimulus_set['stimulus_id'].values\n",
    "train_stimuli, val_stimuli = train_test_split(stimulus_ids, train_size=0.8, random_state=SEED)\n",
    "linear_readout = LogisticRegression(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWThTJTSSs0V",
    "outputId": "2bbafb29-0795-41bb-ba08-a419b3641a41"
   },
   "outputs": [],
   "source": [
    "'''%% Report the validation accuracy of decoding the object category from IT activity and the chance performance of this classification. %%'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATA7UMfKu66F"
   },
   "source": [
    "### Model alignment using RDM\n",
    "\n",
    "In this section, please align two different models to the IT activations using RDM. These models are:\n",
    "\n",
    "- **Gabor filtering:** a set of simple filters for edge detection.\n",
    "- **AlexNet:** an artificial deep neural network trained on the object recognition task. We will provide its activations for the stimuli as an `xarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAKhUMuWc7bE"
   },
   "source": [
    "#### Align Gabor filtering to IT activity\n",
    "\n",
    "Please compute the RDM alignment between activations from a set of Gabor filters and those from monkey IT. As a reminder, a Gabor filter is:\n",
    "\n",
    "$$g(x,y) = s(x,y)~w(x,y)$$\n",
    "where\n",
    "$$ s(x,y) = cos\\left( \\frac{2\\pi x'}{\\lambda} \\right) $$\n",
    "$$ w(x,y) = exp \\left( - \\frac{{x'}^2 + \\gamma^2 {y'}^2}{2 \\sigma^2} \\right) $$\n",
    "and\n",
    "$$x' = cos\\theta~x + sin\\theta~y$$\n",
    "$$y' = -sin\\theta~x + cos\\theta~y$$\n",
    "\n",
    "Please use the following parameters for the Gabor filters:\n",
    "1. `kernel_size` set to 25\n",
    "2. $\\theta=90, 45, 0, -45¬∞$ (convert them to radians)\n",
    "3. $\\lambda= 0.1, 0.3, 1, 3, 9$\n",
    "4. $\\gamma= 0.25, 0.5, 1, 2, 4$\n",
    "5. $\\sigma= 0.8\\lambda$\n",
    "\n",
    "**Hint:** you can adapt codes from *exercise6 : Alignment between Gabor filtering and monkey V1 activity* and other parts of *exercise6*. \\\\\n",
    "**Hint:** do you think the Gabor filtering will align to the IT?\n",
    "\n",
    "The following are some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "dg-DygFtcffn"
   },
   "outputs": [],
   "source": [
    "# generate a square mesh grid of certain size\n",
    "def meshgrid(kernel_size):\n",
    "    return np.mgrid[:kernel_size, :kernel_size] - (kernel_size // 2)\n",
    "\n",
    "# we use an efficient convolution implementation in opencv\n",
    "def convolve2d(img, filter):\n",
    "    return cv2.filter2D(img, -1, filter)\n",
    "\n",
    "# to speed up computations, we downsample the images\n",
    "def downsample(img, factor=4):\n",
    "    return img[..., ::factor, ::factor]\n",
    "\n",
    "# you need to pass in 'gabor_filter_bank', which is a set of Gabor filters\n",
    "def gabor_filtering(img, gabor_filter_bank):\n",
    "  # normalize the image\n",
    "  img = (img - 0.5) / 0.5\n",
    "  gabor_outputs = []\n",
    "  for gabor_filter in gabor_filter_bank:\n",
    "      gabor_outputs.append(downsample(convolve2d(img, gabor_filter)))\n",
    "\n",
    "  gabor_outputs = np.array(gabor_outputs).flatten()\n",
    "\n",
    "  # we add a simple nonlinearity into the system\n",
    "  # by making only \"neurons\" with positive potential fire\n",
    "  gabor_outputs[gabor_outputs<0] = 0\n",
    "\n",
    "  return gabor_outputs\n",
    "\n",
    "# you need to pass in the RDMs of Gabor filtering and IT data\n",
    "def rdm_metric(rdm1, rdm2):\n",
    "    rdm1_upper_tri = rdm1[np.triu_indices(rdm1.shape[0], k=1)]\n",
    "    rdm2_upper_tri = rdm2[np.triu_indices(rdm2.shape[0], k=1)]\n",
    "    return np.corrcoef(rdm1_upper_tri, rdm2_upper_tri)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtmmSO2ZeUUi"
   },
   "outputs": [],
   "source": [
    "'''%% Report the RDM alignment between the Gabor filtering and IT activity %%'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJvDzpHvftgk"
   },
   "source": [
    "#### Align AlexNet to IT activity\n",
    "\n",
    "Please use the AlexNet activations to align to the IT using RDM. Report the RDM alignment score.\n",
    "\n",
    "[AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) is a hierarchical artificial neural network that includes multiple layers of convolutions, nonlinear activation functions, and a multi-layer classifier for predicting the object category. The weights of the convolutions are learned -- they are optimized so that the final layer can predict the object category of the input image. This is very different from Gabor filters, where the weights (or parameters) are pre-determined.\n",
    "\n",
    "Here, we give you the activations from the last convolution layer of AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8hnlwZUxJFR",
    "outputId": "16dcc995-fedf-4115-fefe-375602e8ea0b"
   },
   "outputs": [],
   "source": [
    "from brainio.assemblies import NeuroidAssembly\n",
    "\n",
    "# download\n",
    "url = \"https://github.com/epflneuroailab/bioeng-310/raw/refs/heads/main/week7/alexnet_activations.nc\"\n",
    "!wget -O alexnet_activations.nc $url\n",
    "\n",
    "alexnet_assembly = NeuroidAssembly(xr.open_dataarray('alexnet_activations.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a8ESt5e4LMJ",
    "outputId": "28b92dfe-1f7a-4bb5-e088-f1967283e64f"
   },
   "outputs": [],
   "source": [
    "'''%% Report the RDM alignment between the AlexNet and IT activity %%'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a06d2a26de140308ab77dfea1fbf85a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "153923c0a5d244fa8b198c868aac903c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "252ac3a977bf45ef9ee5450f2582b1a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47c843a94dc34c07b7d6efb623ea0373": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f4ddaf7bbb043b587e89b4feb4843f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a188d6be7eff4855a8f5fb66381e6bb9",
       "IPY_MODEL_b5eab5de7b674341bca1000f408889f9",
       "IPY_MODEL_928e80ca9bdd4bb193d1014941b426a7"
      ],
      "layout": "IPY_MODEL_cb2d4fde44d74ede99668a1f22c59322"
     }
    },
    "83d9e8f755414542a26b0491152a73e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "928e80ca9bdd4bb193d1014941b426a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba5c4596b0bd43e084430ff901e10d45",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_252ac3a977bf45ef9ee5450f2582b1a6",
      "value": "‚Äá135/135‚Äá[02:44&lt;00:00,‚Äá‚Äá1.12s/it]"
     }
    },
    "a188d6be7eff4855a8f5fb66381e6bb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47c843a94dc34c07b7d6efb623ea0373",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_153923c0a5d244fa8b198c868aac903c",
      "value": "Processing‚Äástimuli:‚Äá100%"
     }
    },
    "b5eab5de7b674341bca1000f408889f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a06d2a26de140308ab77dfea1fbf85a",
      "max": 135,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83d9e8f755414542a26b0491152a73e6",
      "value": 135
     }
    },
    "ba5c4596b0bd43e084430ff901e10d45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb2d4fde44d74ede99668a1f22c59322": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
